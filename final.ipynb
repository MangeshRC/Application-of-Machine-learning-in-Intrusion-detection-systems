{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4955667a",
   "metadata": {},
   "source": [
    "## Case Study 1 : Final Submission\n",
    "<br>\n",
    "<li> This notebook has two functions. function1 takes one or more inputs and predicts the output for those points. </li>\n",
    "<li> function2 takes X and Y as inputs in numpy array format and gives AUC score for prediction with the pretrained model. </li>\n",
    "<li> Ensemble model with 10 base learners was used since this was the most efficient model to detect attacks. Base learners are Decision tree models. </li>\n",
    "<li> Each base learner is trained on samples from huge data with 1.5 million datapoints. </li>\n",
    "<li> pickle file with all model and preprocessing details was generated wtih the last cell in Model Testing Notebook </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ce5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required Libraries\n",
    "\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c9034",
   "metadata": {},
   "source": [
    "### 1. Defining function1 and function2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872242fd",
   "metadata": {},
   "source": [
    "#### 1.1 \"function1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df089e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(X):\n",
    "    '''\n",
    "        1.  This function takes input in numpy array format and predicts\n",
    "            whether the input datapoint is an attack or not.\n",
    "        2.  The input can be a single point or an array of points.\n",
    "    '''\n",
    "    \n",
    "    # Loading all saved models, scalar objects and encoder objects\n",
    "    # All these objects were saved in a list structured as follows:\n",
    "    #    [ref_dict,[encoder,scalar],[base_learners]]\n",
    "    \n",
    "    all_saved_data = pickle.load(open(\"all_saved_data.pkl\",\"rb\"))\n",
    "    ref_dict = all_saved_data[0]      # Loading ref_dict which has column index for each feature\n",
    "    preprocessing = all_saved_data[1] # loading encoder and scalar objects\n",
    "    sig_clf = all_saved_data[2]       # loading 10 base learners\n",
    "    \n",
    "    \n",
    "    def predict_point(test_point):\n",
    "        '''\n",
    "            This function performs all preprocessing and predicts output for a single point\n",
    "        '''\n",
    "        \n",
    "        # encoding Categorical Features\n",
    "        proto_test = preprocessing[0]['proto'].transform(\n",
    "            np.array(test_point[ref_dict['proto']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        state_test = preprocessing[0]['state'].transform(\n",
    "            np.array(test_point[ref_dict['state']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        service_test = preprocessing[0]['service'].transform(\n",
    "            np.array(test_point[ref_dict['service']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        is_sm_ips_ports_test = preprocessing[0]['is_sm_ips_ports'].transform(\n",
    "            np.array(test_point[ref_dict['is_sm_ips_ports']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        ct_state_ttl_test = preprocessing[0]['ct_state_ttl'].transform(\n",
    "            np.array(test_point[ref_dict['ct_state_ttl']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        # sclaling numerical features\n",
    "\n",
    "        sport_test = preprocessing[1]['sport'].transform(\n",
    "            np.array(test_point[ref_dict['sport']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dsport_test = preprocessing[1]['dsport'].transform(\n",
    "            np.array(test_point[ref_dict['dsport']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dur_test = preprocessing[1]['dur'].transform(\n",
    "            np.array(test_point[ref_dict['dur']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sbytes_test = preprocessing[1]['sbytes'].transform(\n",
    "            np.array(test_point[ref_dict['sbytes']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dbytes_test = preprocessing[1]['dbytes'].transform(\n",
    "            np.array(test_point[ref_dict['dbytes']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sttl_test = preprocessing[1]['sttl'].transform(\n",
    "            np.array(test_point[ref_dict['sttl']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dttl_test = preprocessing[1]['dttl'].transform(\n",
    "            np.array(test_point[ref_dict['dttl']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sbytes_test = preprocessing[1]['sbytes'].transform(\n",
    "            np.array(test_point[ref_dict['sbytes']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sloss_test = preprocessing[1]['sloss'].transform(\n",
    "            np.array(test_point[ref_dict['sloss']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dloss_test = preprocessing[1]['dloss'].transform(\n",
    "            np.array(test_point[ref_dict['dloss']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Sload_test = preprocessing[1]['Sload'].transform(\n",
    "            np.array(test_point[ref_dict['Sload']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Dload_test = preprocessing[1]['Dload'].transform(\n",
    "            np.array(test_point[ref_dict['Dload']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Spkts_test = preprocessing[1]['Spkts'].transform(\n",
    "            np.array(test_point[ref_dict['Spkts']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Dpkts_test = preprocessing[1]['Dpkts'].transform(\n",
    "            np.array(test_point[ref_dict['Dpkts']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        swin_test = preprocessing[1]['swin'].transform(\n",
    "            np.array(test_point[ref_dict['swin']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dwin_test = preprocessing[1]['dwin'].transform(\n",
    "            np.array(test_point[ref_dict['dwin']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        stcpb_test = preprocessing[1]['stcpb'].transform(\n",
    "            np.array(test_point[ref_dict['stcpb']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dtcpb_test = preprocessing[1]['dtcpb'].transform(\n",
    "            np.array(test_point[ref_dict['dtcpb']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        smeansz_test = preprocessing[1]['smeansz'].transform(\n",
    "            np.array(test_point[ref_dict['smeansz']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dmeansz_test = preprocessing[1]['dmeansz'].transform(\n",
    "            np.array(test_point[ref_dict['dmeansz']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        trans_depth_test = preprocessing[1]['trans_depth'].transform(\n",
    "            np.array(test_point[ref_dict['trans_depth']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        res_bdy_len_test = preprocessing[1]['res_bdy_len'].transform(\n",
    "            np.array(test_point[ref_dict['res_bdy_len']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Sjit_test = preprocessing[1]['Sjit'].transform(\n",
    "            np.array(test_point[ref_dict['Sjit']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Djit_test = preprocessing[1]['Djit'].transform(\n",
    "            np.array(test_point[ref_dict['Djit']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Sintpkt_test = preprocessing[1]['Sintpkt'].transform(\n",
    "            np.array(test_point[ref_dict['Sintpkt']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Dintpkt_test = preprocessing[1]['Dintpkt'].transform(\n",
    "            np.array(test_point[ref_dict['Dintpkt']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        tcprtt_test = preprocessing[1]['tcprtt'].transform(\n",
    "            np.array(test_point[ref_dict['tcprtt']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        synack_test = preprocessing[1]['synack'].transform(\n",
    "            np.array(test_point[ref_dict['synack']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ackdat_test = preprocessing[1]['ackdat'].transform(\n",
    "            np.array(test_point[ref_dict['ackdat']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_srv_src_test = preprocessing[1]['ct_srv_src'].transform(\n",
    "            np.array(test_point[ref_dict['ct_srv_src']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_srv_dst_test = preprocessing[1]['ct_srv_dst'].transform(\n",
    "            np.array(test_point[ref_dict['ct_srv_dst']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_dst_ltm_test = preprocessing[1]['ct_dst_ltm'].transform(\n",
    "            np.array(test_point[ref_dict['ct_dst_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_src_ltm_test = preprocessing[1]['ct_src_ltm'].transform(\n",
    "            np.array(test_point[ref_dict['ct_src_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_src_dport_ltm_test = preprocessing[1]['ct_src_dport_ltm'].transform(\n",
    "            np.array(test_point[ref_dict['ct_src_dport_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_dst_sport_ltm_test = preprocessing[1]['ct_dst_sport_ltm'].transform(\n",
    "            np.array(test_point[ref_dict['ct_dst_sport_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        \n",
    "        # Stacking all the generated features\n",
    "        X_test = hstack((proto_test,state_test,service_test,is_sm_ips_ports_test,ct_state_ttl_test,\n",
    "                                sport_test,dsport_test,dur_test,sbytes_test,dbytes_test,sttl_test,dttl_test,\n",
    "                                sloss_test,dloss_test,Sload_test,Dload_test,Spkts_test,Dpkts_test,swin_test,\n",
    "                                dwin_test,stcpb_test,dtcpb_test,smeansz_test,dmeansz_test,trans_depth_test,\n",
    "                                res_bdy_len_test,Sjit_test,Djit_test,Sintpkt_test,Dintpkt_test,\n",
    "                                tcprtt_test,synack_test,ackdat_test,ct_srv_src_test,ct_srv_dst_test,ct_dst_ltm_test,\n",
    "                                ct_src_ltm_test,ct_src_ltm_test,ct_src_dport_ltm_test,ct_dst_sport_ltm_test))\n",
    "\n",
    "        \n",
    "        # Predicting X_test points with all base learners.\n",
    "        y_pred = []\n",
    "        for j in range(10):  # iterating through all 10 base learners\n",
    "            y_pred.append(sig_clf[j].predict_proba(X_test))\n",
    "        \n",
    "        # taking mean of predictions from all base learners\n",
    "        y_pred = np.array(y_pred)[:,0]\n",
    "        y_pred = np.mean(y_pred[:,1])>0.5 # flag to indicate attack or not\n",
    "\n",
    "        if y_pred:\n",
    "            return \"The given datapoint is an attack\"\n",
    "        else:\n",
    "            return \"The given datapoint is not an attack\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # If single datapoint is provied then shape length will be 1\n",
    "        if len(X.shape) == 1:\n",
    "            return predict_point(X)\n",
    "        # else length will be 2 and a loop is written to iterate through all datapoints\n",
    "        elif len(X.shape) == 2:\n",
    "            prediction = []\n",
    "            for point in X:\n",
    "                prediction.append(predict_point(point))\n",
    "            return prediction\n",
    "        else:\n",
    "            print(\"Please provide a Numpy array of one or more datapoints\")\n",
    "    except:\n",
    "        print(\"Please provide a valid input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea590c3",
   "metadata": {},
   "source": [
    "#### 1.2 \"function2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e1669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(X,Y):\n",
    "    '''\n",
    "        1.  This function takes datapoints and their Label as input and\n",
    "            calculates AUC score\n",
    "        2.  Both X & Y should be numpy arrays\n",
    "    '''\n",
    "    \n",
    "    # Loading all saved models, scalar objects and encoder objects\n",
    "    # All these objects were saved in a list structured as follows:\n",
    "    #    [ref_dict,[encoder,scalar],[base_learners]]\n",
    "    \n",
    "    all_saved_data = pickle.load(open(\"all_saved_data.pkl\",\"rb\"))\n",
    "    ref_dict = all_saved_data[0]\n",
    "    preprocessing = all_saved_data[1]\n",
    "    sig_clf = all_saved_data[2]\n",
    "    \n",
    "    \n",
    "    def predict_proba(test_points):\n",
    "        '''\n",
    "            This function takes datapoints as inputs and performs all preprocessing\n",
    "            and returns the prediction probability for those input points\n",
    "        '''\n",
    "        \n",
    "        # encoding Categorical Features\n",
    "        proto_test = preprocessing[0]['proto'].transform(\n",
    "            np.array(test_points[:,ref_dict['proto']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        state_test = preprocessing[0]['state'].transform(\n",
    "            np.array(test_points[:,ref_dict['state']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        service_test = preprocessing[0]['service'].transform(\n",
    "            np.array(test_points[:,ref_dict['service']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        is_sm_ips_ports_test = preprocessing[0]['is_sm_ips_ports'].transform(\n",
    "            np.array(test_points[:,ref_dict['is_sm_ips_ports']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        ct_state_ttl_test = preprocessing[0]['ct_state_ttl'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_state_ttl']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        # scaling numerical features\n",
    "\n",
    "        sport_test = preprocessing[1]['sport'].transform(\n",
    "            np.array(test_points[:,ref_dict['sport']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dsport_test = preprocessing[1]['dsport'].transform(\n",
    "            np.array(test_points[:,ref_dict['dsport']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dur_test = preprocessing[1]['dur'].transform(\n",
    "            np.array(test_points[:,ref_dict['dur']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sbytes_test = preprocessing[1]['sbytes'].transform(\n",
    "            np.array(test_points[:,ref_dict['sbytes']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dbytes_test = preprocessing[1]['dbytes'].transform(\n",
    "            np.array(test_points[:,ref_dict['dbytes']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sttl_test = preprocessing[1]['sttl'].transform(\n",
    "            np.array(test_points[:,ref_dict['sttl']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dttl_test = preprocessing[1]['dttl'].transform(\n",
    "            np.array(test_points[:,ref_dict['dttl']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sbytes_test = preprocessing[1]['sbytes'].transform(\n",
    "            np.array(test_points[:,ref_dict['sbytes']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        sloss_test = preprocessing[1]['sloss'].transform(\n",
    "            np.array(test_points[:,ref_dict['sloss']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dloss_test = preprocessing[1]['dloss'].transform(\n",
    "            np.array(test_points[:,ref_dict['dloss']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Sload_test = preprocessing[1]['Sload'].transform(\n",
    "            np.array(test_points[:,ref_dict['Sload']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Dload_test = preprocessing[1]['Dload'].transform(\n",
    "            np.array(test_points[:,ref_dict['Dload']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Spkts_test = preprocessing[1]['Spkts'].transform(\n",
    "            np.array(test_points[:,ref_dict['Spkts']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Dpkts_test = preprocessing[1]['Dpkts'].transform(\n",
    "            np.array(test_points[:,ref_dict['Dpkts']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        swin_test = preprocessing[1]['swin'].transform(\n",
    "            np.array(test_points[:,ref_dict['swin']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dwin_test = preprocessing[1]['dwin'].transform(\n",
    "            np.array(test_points[:,ref_dict['dwin']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        stcpb_test = preprocessing[1]['stcpb'].transform(\n",
    "            np.array(test_points[:,ref_dict['stcpb']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dtcpb_test = preprocessing[1]['dtcpb'].transform(\n",
    "            np.array(test_points[:,ref_dict['dtcpb']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        smeansz_test = preprocessing[1]['smeansz'].transform(\n",
    "            np.array(test_points[:,ref_dict['smeansz']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        dmeansz_test = preprocessing[1]['dmeansz'].transform(\n",
    "            np.array(test_points[:,ref_dict['dmeansz']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        trans_depth_test = preprocessing[1]['trans_depth'].transform(\n",
    "            np.array(test_points[:,ref_dict['trans_depth']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        res_bdy_len_test = preprocessing[1]['res_bdy_len'].transform(\n",
    "            np.array(test_points[:,ref_dict['res_bdy_len']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Sjit_test = preprocessing[1]['Sjit'].transform(\n",
    "            np.array(test_points[:,ref_dict['Sjit']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Djit_test = preprocessing[1]['Djit'].transform(\n",
    "            np.array(test_points[:,ref_dict['Djit']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Sintpkt_test = preprocessing[1]['Sintpkt'].transform(\n",
    "            np.array(test_points[:,ref_dict['Sintpkt']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        Dintpkt_test = preprocessing[1]['Dintpkt'].transform(\n",
    "            np.array(test_points[:,ref_dict['Dintpkt']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        tcprtt_test = preprocessing[1]['tcprtt'].transform(\n",
    "            np.array(test_points[:,ref_dict['tcprtt']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        synack_test = preprocessing[1]['synack'].transform(\n",
    "            np.array(test_points[:,ref_dict['synack']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ackdat_test = preprocessing[1]['ackdat'].transform(\n",
    "            np.array(test_points[:,ref_dict['ackdat']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_srv_src_test = preprocessing[1]['ct_srv_src'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_srv_src']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_srv_dst_test = preprocessing[1]['ct_srv_dst'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_srv_dst']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_dst_ltm_test = preprocessing[1]['ct_dst_ltm'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_dst_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_src_ltm_test = preprocessing[1]['ct_src_ltm'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_src_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_src_dport_ltm_test = preprocessing[1]['ct_src_dport_ltm'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_src_dport_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "        ct_dst_sport_ltm_test = preprocessing[1]['ct_dst_sport_ltm'].transform(\n",
    "            np.array(test_points[:,ref_dict['ct_dst_sport_ltm']],dtype='object').reshape(-1,1))\n",
    "\n",
    "\n",
    "        X_test = hstack((proto_test,state_test,service_test,is_sm_ips_ports_test,ct_state_ttl_test,\n",
    "                                sport_test,dsport_test,dur_test,sbytes_test,dbytes_test,sttl_test,dttl_test,\n",
    "                                sloss_test,dloss_test,Sload_test,Dload_test,Spkts_test,Dpkts_test,swin_test,\n",
    "                                dwin_test,stcpb_test,dtcpb_test,smeansz_test,dmeansz_test,trans_depth_test,\n",
    "                                res_bdy_len_test,Sjit_test,Djit_test,Sintpkt_test,Dintpkt_test,\n",
    "                                tcprtt_test,synack_test,ackdat_test,ct_srv_src_test,ct_srv_dst_test,ct_dst_ltm_test,\n",
    "                                ct_src_ltm_test,ct_src_ltm_test,ct_src_dport_ltm_test,ct_dst_sport_ltm_test))\n",
    "\n",
    "        \n",
    "        # Predicting X_test points with all base learners.\n",
    "        y_pred = []\n",
    "        for j in range(10):\n",
    "            y_pred.append(sig_clf[j].predict_proba(X_test))\n",
    "        \n",
    "        # Getting final prediction for each datapoint with taking mean of \n",
    "        # predictions with all base_learners.\n",
    "        predicted_y = []  # empty list to store predictions\n",
    "        for i in tqdm(range(X_test.shape[0])):   # Loop to iterate through all datapoints\n",
    "            temp = []\n",
    "            for j in range(10):                # Loop to iterate through all base learners\n",
    "                temp.append(y_pred[j][i][1])\n",
    "            predicted_y.append(np.mean(temp))  # Taking mean of all base learner predictions\n",
    "\n",
    "        return predicted_y\n",
    "    \n",
    "    if len(X.shape) == 1:\n",
    "        print(\"AUC Score can not be calculated for one point\")\n",
    "    elif len(X.shape) == 2:\n",
    "        prediction = predict_proba(X)\n",
    "        return \"AUC Score for given datapoints is : {}\".format(roc_auc_score(Y,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832a8d1",
   "metadata": {},
   "source": [
    "### 2. Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5126cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_data.csv\",nrows=1000000)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddb7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Label'],axis=1).values\n",
    "Y = data['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73aa11b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The given datapoint is not an attack'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for one point with function1\n",
    "\n",
    "function1(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154044cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack',\n",
       " 'The given datapoint is not an attack']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction for multiple points with function1\n",
    "\n",
    "function1(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb2d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1000000/1000000 [00:13<00:00, 72660.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AUC Score for given datapoints is : 0.9999989400247669'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting AUC for complete data with function2\n",
    "\n",
    "function2(X,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
